{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  143550\n",
      "Total Vocab:  42\n"
     ]
    }
   ],
   "source": [
    "# Load Larger LSTM network and generate text\n",
    "import sys\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "# load ascii text and covert to lowercase\n",
    "filename = \"d:/machine learning/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()\n",
    "# create mapping of unique chars to integers, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "# summarize the loaded data\n",
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  143450\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "\tseq_in = raw_text[i:i + seq_length]\n",
    "\tseq_out = raw_text[i + seq_length]\n",
    "\tdataX.append([char_to_int[char] for char in seq_in])\n",
    "\tdataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print( \"Total Patterns: \", n_patterns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0730 08:05:29.860978 15764 deprecation_wrapper.py:119] From C:\\Users\\Tony Diana\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0730 08:05:30.109389 15764 deprecation_wrapper.py:119] From C:\\Users\\Tony Diana\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(LSTM(256))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "# load the network weights\n",
    "filename = \"d:/machine learning/weights-improvement-02-2.6854.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" frame, or something of the sort.\n",
      "\n",
      "next came an angry voice--the rabbit's--'pat! pat! where are you?' \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print( \"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.31128095e-02 3.12280916e-02 3.00940406e-02 ... 1.90802068e-02\n",
      "   2.24800818e-02 1.96601376e-02]\n",
      "  [1.72385685e-02 9.80789065e-02 3.67218181e-02 ... 4.47185151e-03\n",
      "   2.49972958e-02 1.12032574e-02]\n",
      "  [2.77334396e-02 1.88526228e-01 1.67463124e-02 ... 7.06118240e-04\n",
      "   2.88389251e-02 3.44211841e-03]\n",
      "  ...\n",
      "  [1.66888945e-02 3.63601327e-01 3.89477820e-03 ... 1.17283089e-04\n",
      "   2.70461943e-02 1.05317379e-03]\n",
      "  [1.46762645e-02 1.48606196e-01 2.23134086e-03 ... 2.83287925e-04\n",
      "   8.84336513e-03 1.05503155e-03]\n",
      "  [9.83386412e-02 1.20523885e-01 8.58272891e-04 ... 1.27915887e-03\n",
      "   1.38617000e-02 2.60110566e-04]]]\n"
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\t#index = numpy.argmax(prediction)\n",
    "\t#result = int_to_char[value]\n",
    "\t#seq_in = [int_to_char[value] for value in pattern]\n",
    "\t#sys.stdout.write(result)\n",
    "\t#pattern.append(index)\n",
    "\t#pattern = pattern[1:len(pattern)]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.31128095e-02 3.12280916e-02 3.00940406e-02 ... 1.90802068e-02\n",
      "   2.24800818e-02 1.96601376e-02]\n",
      "  [1.72385685e-02 9.80789065e-02 3.67218181e-02 ... 4.47185151e-03\n",
      "   2.49972958e-02 1.12032574e-02]\n",
      "  [2.77334396e-02 1.88526228e-01 1.67463124e-02 ... 7.06118240e-04\n",
      "   2.88389251e-02 3.44211841e-03]\n",
      "  ...\n",
      "  [1.66888945e-02 3.63601327e-01 3.89477820e-03 ... 1.17283089e-04\n",
      "   2.70461943e-02 1.05317379e-03]\n",
      "  [1.46762645e-02 1.48606196e-01 2.23134086e-03 ... 2.83287925e-04\n",
      "   8.84336513e-03 1.05503155e-03]\n",
      "  [9.83386412e-02 1.20523885e-01 8.58272891e-04 ... 1.27915887e-03\n",
      "   1.38617000e-02 2.60110566e-04]]]\n"
     ]
    }
   ],
   "source": [
    "print(str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
